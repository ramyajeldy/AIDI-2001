{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc6c550",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fa42fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install transformers datasets torch\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc222c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "087fc547",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 1: What Is a Language Model?\n",
    "\n",
    "A language model does one thing: **predict the next token** in a sequence.\n",
    "\n",
    "Given `\"The cat sat on the\"`, it assigns probabilities:\n",
    "\n",
    "| Next Word | Probability |\n",
    "|-----------|-------------|\n",
    "| mat       | 0.35        |\n",
    "| floor     | 0.25        |\n",
    "| chair     | 0.15        |\n",
    "| ...       | ...         |\n",
    "\n",
    "That is it. Every conversation, every essay, every piece of code an LLM generates comes from repeatedly picking the next most likely token.\n",
    "\n",
    "Most modern LLMs use the **Transformer** architecture (from *\"Attention Is All You Need\"*, 2017). The key idea is an **attention mechanism** that lets each word look at every other word to determine context. This is how the model knows \"bank\" means something different in \"river bank\" vs. \"bank loan.\"\n",
    "\n",
    "Let's see this in action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069ebc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 76/76 [00:00<00:00, 532.39it/s, Materializing param=transformer.wte.weight]            \n",
      "GPT2LMHeadModel LOAD REPORT from: distilgpt2\n",
      "Key                                        | Status     |  | \n",
      "-------------------------------------------+------------+--+-\n",
      "transformer.h.{0, 1, 2, 3, 4, 5}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=25) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The cat sat on the counter of a shopping centre, sat in the centre of a shopping centre.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a small language model\n",
    "generator = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=\"distilgpt2\", \n",
    "    max_new_tokens=25,\n",
    "    )\n",
    "\n",
    "# Watch it predict\n",
    "prompt = \"The cat sat on the\"\n",
    "result = generator(prompt)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34da9ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d3bc8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86328ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated_text': 'The cat sat on the counter of a shopping centre, sat in the centre of a shopping centre.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Model completed:\", result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf2511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da6c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0791efb7",
   "metadata": {},
   "source": [
    "### Before You Continue — Predict\n",
    "\n",
    "What do you think will happen if we ask this model:\n",
    "\n",
    "> \"Our clothing store's return policy allows customers to\"\n",
    "\n",
    "Write down your prediction. Then run the next cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72ca667",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 2: The Failure\n",
    "\n",
    "We want to build a chatbot for **BlueSky Clothing Store**. It should answer questions about store hours, return policies, shipping, and sizing.\n",
    "\n",
    "Let's try.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c85ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\", max_new_tokens=50)\n",
    "\n",
    "# Ask the model about our store\n",
    "questions = [\n",
    "    \"What is BlueSky Clothing's return policy?\",\n",
    "    \"What are your store hours?\",\n",
    "    \"Do you offer free shipping on orders over $75?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    result = generator(q)\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"A: {result[0]['generated_text']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab00f52",
   "metadata": {},
   "source": [
    "### Stop and Analyze\n",
    "\n",
    "The model produced *something* for each question. But examine the outputs carefully.\n",
    "\n",
    "**Questions you must answer before continuing:**\n",
    "\n",
    "1. Are any of the answers factually correct about BlueSky Clothing?\n",
    "2. Did the model refuse to answer, or did it generate a confident-sounding response?\n",
    "3. If a customer received these answers, what would happen?\n",
    "\n",
    "The model is not broken. It is doing exactly what it was trained to do: predict likely next tokens based on internet text. It has never seen BlueSky Clothing's data.\n",
    "\n",
    "This is the core problem: **the model is capable, but uninformed.**\n",
    "\n",
    "Now the question becomes: *How do we give it the right information?*\n",
    "\n",
    "Think of at least two different approaches before reading on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a9b6bc",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 3: First Fix — Prompt Engineering\n",
    "\n",
    "The cheapest possible intervention: **change the input, not the model.**\n",
    "\n",
    "Prompt engineering means crafting your input to guide the model's behavior. No retraining. No new data pipelines. Just better instructions.\n",
    "\n",
    "A well-structured prompt has these components:\n",
    "\n",
    "| Component | Required? | Purpose |\n",
    "|-----------|-----------|---------|\n",
    "| **System prompt** | Optional (but powerful) | Sets the model's role and constraints |\n",
    "| **Context** | Optional | Provides reference information |\n",
    "| **User prompt** | Required | The actual question |\n",
    "\n",
    "Most users skip the system prompt. This is a mistake — it can produce materially better results.\n",
    "\n",
    "Let's see if structuring our prompt fixes the failure from Section 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a32dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 1: Add a system prompt\n",
    "structured_prompt = \"You are a customer service assistant for BlueSky Clothing Store.\\nYou are helpful, accurate, and concise.\\n\\nCustomer question: What is your return policy?\\nAssistant response:\"\n",
    "\n",
    "result = generator(structured_prompt, max_new_tokens=50)\n",
    "print(\"With system prompt:\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a582c18",
   "metadata": {},
   "source": [
    "### Did It Work?\n",
    "\n",
    "Examine the output. The model now *knows* it should act as a store assistant. But does it know the actual return policy?\n",
    "\n",
    "Likely not. The system prompt changed the **tone and role**, but it cannot inject **facts the model has never seen**.\n",
    "\n",
    "Let's try harder — few-shot prompting. We give the model examples of correct answers and hope it follows the pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148037fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2: Few-shot prompting\n",
    "few_shot_prompt = \"Customer: What are your store hours?\\nAssistant: We are open Monday-Friday 9am-6pm, Saturday 10am-4pm.\\n\\nCustomer: Do you offer gift wrapping?\\nAssistant: Yes, complimentary gift wrapping on purchases over $25.\\n\\nCustomer: What is your return policy?\\nAssistant:\"\n",
    "\n",
    "result = generator(few_shot_prompt, max_new_tokens=40)\n",
    "print(\"With few-shot examples:\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7346cb",
   "metadata": {},
   "source": [
    "### Progress Check\n",
    "\n",
    "Few-shot prompting is better. The model follows the format and may even generate a plausible-sounding return policy. But here is the critical question:\n",
    "\n",
    "**Is the return policy it generated actually BlueSky's policy?**\n",
    "\n",
    "If the real policy is \"30 days with receipt, sale items final sale,\" and the model generates \"14 days, no exceptions\" — that is worse than no answer at all. The customer receives a confident, authoritative, *wrong* answer.\n",
    "\n",
    "**What prompt engineering can fix:**\n",
    "- Tone, format, role, style\n",
    "- Output structure (JSON, bullet points, etc.)\n",
    "- Reasoning approach (chain-of-thought)\n",
    "\n",
    "**What prompt engineering cannot fix:**\n",
    "- Missing factual knowledge\n",
    "- Domain-specific details the model was never trained on\n",
    "\n",
    "We need a different approach for the knowledge problem.\n",
    "\n",
    "### Try It\n",
    "\n",
    "1. Write three different system prompts for the same question. How does tone change? Does accuracy change?\n",
    "2. What happens if your few-shot examples contradict each other? Try it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023228f4",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 4: Second Fix — Retrieval Augmented Generation (RAG)\n",
    "\n",
    "Instead of hoping the model knows the answer, **give it the answer as part of the prompt.**\n",
    "\n",
    "RAG works in two steps:\n",
    "1. **Retrieve** relevant information from your knowledge base\n",
    "2. **Generate** a response using that information as context\n",
    "\n",
    "The model's weights never change. You are changing the *input*, not the *model*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Our knowledge base (in production, this would be a vector database)\n",
    "knowledge_base = {\n",
    "    \"return_policy\": (\n",
    "        \"Items can be returned within 30 days with a receipt for a full refund. \"\n",
    "        \"Sale items are final sale. Gift cards are non-refundable.\"\n",
    "    ),\n",
    "    \"store_hours\": (\n",
    "        \"Monday-Friday 9am-6pm, Saturday 10am-4pm, closed Sunday.\"\n",
    "    ),\n",
    "    \"shipping\": (\n",
    "        \"Free shipping on orders over $75. Standard shipping: 5-7 business days. \"\n",
    "        \"Express 2-day shipping available for $12.99.\"\n",
    "    ),\n",
    "    \"sizing\": (\n",
    "        \"We carry sizes XS through 3XL. Size chart at bluesky.com/sizes. \"\n",
    "        \"In-store fittings available by appointment.\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Step 2: Simple retrieval (keyword matching — production uses embeddings)\n",
    "def retrieve(question, kb):\n",
    "    question_lower = question.lower()\n",
    "    best_key, best_score = None, 0\n",
    "    for key, value in kb.items():\n",
    "        keywords = key.replace(\"_\", \" \").split()\n",
    "        score = sum(1 for kw in keywords if kw in question_lower)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_key = key\n",
    "    return kb[best_key] if best_key else \"No relevant information found.\"\n",
    "\n",
    "# Step 3: Build the RAG prompt\n",
    "question = \"What is your return policy?\"\n",
    "context = retrieve(question, knowledge_base)\n",
    "\n",
    "rag_prompt = f\"Use ONLY the following context to answer the question.\\nIf the context does not contain the answer, say \\\"I don't have that information.\\\"\\n\\nContext: {context}\\n\\nCustomer question: {question}\\nAssistant response:\"\n",
    "\n",
    "print(\"Retrieved context:\", context)\n",
    "print()\n",
    "print(\"Full prompt sent to model:\")\n",
    "print(rag_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec429be",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "Compare this to every previous attempt:\n",
    "\n",
    "| Approach | Model weights changed? | Knows BlueSky facts? | Risk of hallucination |\n",
    "|----------|----------------------|---------------------|-----------------------|\n",
    "| Bare prompt | No | No | High |\n",
    "| System prompt | No | No | High |\n",
    "| Few-shot | No | Only from examples | Medium |\n",
    "| **RAG** | **No** | **Yes — from retrieved docs** | **Low** |\n",
    "\n",
    "RAG is powerful because:\n",
    "- The model gets the **exact** information it needs for each query\n",
    "- Your knowledge base can be **updated instantly** without retraining\n",
    "- You can **verify** answers against source documents\n",
    "- It is **dramatically cheaper** than fine-tuning\n",
    "\n",
    "### Try It\n",
    "\n",
    "1. Add a new topic to `knowledge_base` (e.g., loyalty program). Query it.\n",
    "2. Ask a question that spans two topics: *\"Can I return a shipped item?\"* What happens? How would you fix this?\n",
    "3. What happens if the context is very long — say, a 50-page document? What are the limits?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52892e8",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 5: What's Still Missing?\n",
    "\n",
    "We have solved the knowledge problem with RAG. But look at this output from a hypothetical well-built chatbot:\n",
    "\n",
    "---\n",
    "\n",
    "**Customer:** *Can I return the blue silk dress I bought last week? I lost the receipt though.*\n",
    "\n",
    "**Ideal Response:** *I'm sorry to hear you'd like to return the dress! While our standard policy requires a receipt for full refunds, we can look up your purchase using your credit card or loyalty account. If we find the transaction, we can process a return within our 30-day window. Would you like to visit us in store so we can check? We're open Monday-Friday 9am-6pm.*\n",
    "\n",
    "---\n",
    "\n",
    "### Reverse Engineer This Response\n",
    "\n",
    "That response demonstrates several things at once. Identify which technique produced each:\n",
    "\n",
    "1. **Accurate policy details** (30-day window, receipt requirement) — Where did this come from?\n",
    "2. **Empathetic, on-brand tone** — Where did this come from?\n",
    "3. **Proactive problem-solving** (credit card lookup alternative) — Where did this come from?\n",
    "4. **Cross-referencing store hours** — Where did this come from?\n",
    "\n",
    "**The hard question:** Could prompt engineering + RAG produce this response? Or does the model need to *learn* BlueSky's specific communication style?\n",
    "\n",
    "Think about this carefully. Not every gap requires the same solution.\n",
    "\n",
    "- If the tone is wrong: better system prompt\n",
    "- If the facts are wrong: better retrieval\n",
    "- If the *style* is consistently off despite good prompts: maybe the model needs to learn new behavior\n",
    "\n",
    "This is where fine-tuning enters the conversation — not as a first resort, but as an answer to the question: **\"What problems remain after we have tried everything cheaper?\"**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf6b9f",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 6: Fine-Tuning — Adjusting the Model Itself\n",
    "\n",
    "### What Fine-Tuning Actually Is\n",
    "\n",
    "Fine-tuning means taking a **pretrained model** and continuing its training on a **smaller, task-specific dataset**. Unlike prompt engineering and RAG, this changes the model's internal weights.\n",
    "\n",
    "Analogy:\n",
    "- **Pretraining** = General university education\n",
    "- **Fine-tuning** = Professional specialization\n",
    "\n",
    "A critical point from practice: fine-tuning works best when the model has **some prior exposure** to similar data. You are reminding the model of patterns it partially learned during pretraining — like reinforcing a distant memory. If the model has never encountered anything like your domain, fine-tuning will struggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b29e58",
   "metadata": {},
   "source": [
    "### 6.1 Supervised Fine-Tuning (SFT)\n",
    "\n",
    "You provide (instruction, expected response) pairs. The model's weights are updated to minimize the gap between its outputs and your expected responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a9eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What SFT training data looks like\n",
    "sft_data = [\n",
    "    {\"instruction\": \"What is your return policy?\",\n",
    "     \"response\": \"Items can be returned within 30 days with receipt for a full refund. \"\n",
    "                 \"Sale items are final sale. We're happy to help with exchanges too!\"},\n",
    "    {\"instruction\": \"A customer is upset about a late shipment. Respond helpfully.\",\n",
    "     \"response\": \"I completely understand your frustration, and I sincerely apologize \"\n",
    "                 \"for the delay. Let me look into your order right away and see what \"\n",
    "                 \"we can do to make this right.\"},\n",
    "    {\"instruction\": \"What are your store hours?\",\n",
    "     \"response\": \"We're open Monday through Friday 9am to 6pm, and Saturday 10am to 4pm. \"\n",
    "                 \"We'd love to see you! If those times don't work, you can also shop \"\n",
    "                 \"online 24/7 at bluesky.com.\"},\n",
    "]\n",
    "\n",
    "# Notice: these responses encode both FACTS and STYLE.\n",
    "# The facts could come from RAG. The style is what SFT teaches.\n",
    "for entry in sft_data:\n",
    "    print(f\"Instruction: {entry['instruction']}\")\n",
    "    print(f\"Response:    {entry['response'][:80]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0261ed",
   "metadata": {},
   "source": [
    "### 6.2 RLHF — Reinforcement Learning from Human Feedback\n",
    "\n",
    "Instead of one correct answer, the model generates multiple responses and **humans rank them**. A reward model learns these preferences, and the language model is trained to maximize the reward.\n",
    "\n",
    "You may have seen this in ChatGPT — it sometimes shows two answers and asks you to pick the better one. That feedback is RLHF.\n",
    "\n",
    "### 6.3 DPO — Direct Preference Optimization\n",
    "\n",
    "A newer alternative that skips the separate reward model. It directly optimizes using (preferred response, rejected response) pairs, simplifying the pipeline.\n",
    "\n",
    "### When to Use Which\n",
    "\n",
    "| Technique | Input Data | Complexity | Best For |\n",
    "|-----------|-----------|------------|----------|\n",
    "| **SFT** | Instruction-response pairs | Low | Clear correct answers exist |\n",
    "| **RLHF** | Human rankings of outputs | High | Subjective quality (tone, helpfulness) |\n",
    "| **DPO** | Preferred vs. rejected pairs | Medium | RLHF benefits without RL complexity |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bfa7ac",
   "metadata": {},
   "source": [
    "### Try It — Reverse Reasoning\n",
    "\n",
    "Here are two responses to *\"A customer wants to return a worn item.\"*\n",
    "\n",
    "**Response A:** \"Per our policy, worn items cannot be returned.\"\n",
    "\n",
    "**Response B:** \"I understand this is disappointing. Unfortunately, worn items fall outside our return policy. However, I'd be happy to help you find a replacement or explore our exchange options.\"\n",
    "\n",
    "1. Both are factually correct. What makes B better?\n",
    "2. Which fine-tuning technique would you use to get the model to consistently prefer B's style?\n",
    "3. Could you achieve this with prompt engineering alone? What would be the tradeoff?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebea49d",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 7: The Cost Reality\n",
    "\n",
    "Fine-tuning is powerful. It is also expensive. Before committing, do the math.\n",
    "\n",
    "| Cost Factor | What It Means |\n",
    "|-------------|---------------|\n",
    "| **Training compute** | GPU hours to run fine-tuning |\n",
    "| **Data preparation** | Cleaning, formatting, labeling — often the biggest time cost |\n",
    "| **Per-token training** | Services like OpenAI charge per token to fine-tune |\n",
    "| **Inference costs** | Running a custom model costs more than standard API calls |\n",
    "| **Hosting** | Self-hosting requires infrastructure |\n",
    "| **Maintenance** | Domain changes require retraining |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210698af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost estimation exercise\n",
    "# Training costs (approximate — check current rates)\n",
    "training_tokens = 1_000_000\n",
    "cost_per_1k_train = 0.008  # example rate\n",
    "\n",
    "training_cost = (training_tokens / 1000) * cost_per_1k_train\n",
    "\n",
    "# Inference costs (ongoing)\n",
    "daily_queries = 500\n",
    "tokens_per_query = 200\n",
    "cost_per_1k_inference = 0.012\n",
    "\n",
    "monthly_tokens = daily_queries * 30 * tokens_per_query\n",
    "monthly_inference = (monthly_tokens / 1000) * cost_per_1k_inference\n",
    "annual_inference = monthly_inference * 12\n",
    "\n",
    "print(f\"One-time training cost:  ${training_cost:.2f}\")\n",
    "print(f\"Monthly inference cost:  ${monthly_inference:.2f}\")\n",
    "print(f\"Annual inference cost:   ${annual_inference:.2f}\")\n",
    "print(f\"Total year-1 cost:       ${training_cost + annual_inference:.2f}\")\n",
    "print()\n",
    "\n",
    "# Compare: what if RAG + prompt engineering is enough?\n",
    "rag_cost_per_1k = 0.002  # standard model, no fine-tuning\n",
    "rag_monthly = (monthly_tokens / 1000) * rag_cost_per_1k\n",
    "print(f\"RAG-only monthly cost:   ${rag_monthly:.2f}\")\n",
    "print(f\"RAG-only annual cost:    ${rag_monthly * 12:.2f}\")\n",
    "print(f\"\\nFine-tuning costs {annual_inference / (rag_monthly * 12):.1f}x more per year at inference alone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12228d50",
   "metadata": {},
   "source": [
    "### Try It\n",
    "\n",
    "1. Change `daily_queries` to 5,000. How does the cost gap change?\n",
    "2. At what query volume does annual cost exceed hiring a part-time employee ($25,000/year)?\n",
    "3. If store policies change quarterly, what is the hidden cost of retraining each time?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf294f9",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 8: Decision Framework\n",
    "\n",
    "### Comparison\n",
    "\n",
    "| | Prompt Engineering | RAG | Fine-Tuning |\n",
    "|---|---|---|---|\n",
    "| **Cost** | Very low | Low-Medium | High |\n",
    "| **Setup time** | Minutes | Days | Weeks |\n",
    "| **Data needed** | None | Documents | Labeled pairs (100s-1000s) |\n",
    "| **Updates** | Edit prompt | Update doc store | Retrain |\n",
    "| **Solves** | Format, tone, role | Knowledge gaps | Behavior, style, niche tasks |\n",
    "| **Limits** | Cannot inject facts | Retrieval quality | Expensive, can overfit |\n",
    "\n",
    "### The Decision Path\n",
    "\n",
    "1. **Start with prompt engineering.** It is fast, cheap, and reversible. Does it solve the problem? Stop here.\n",
    "2. **Add RAG if the model needs domain knowledge.** Facts, documents, policies — retrieve them at query time.\n",
    "3. **Consider fine-tuning only if** the model needs to learn a fundamentally new behavior, style, or capability that prompting cannot capture consistently.\n",
    "4. **In practice, combine approaches.** The best production systems often use all three: fine-tuning for style, RAG for knowledge, prompt engineering for structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9affde9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario analysis — test your reasoning\n",
    "scenarios = [\n",
    "    (\"A startup needs a bot for their 50-page FAQ.\",\n",
    "     \"RAG\", \"Knowledge is in documents, changes often, limited resources.\"),\n",
    "\n",
    "    (\"A law firm wants briefs written in their specific house style.\",\n",
    "     \"Fine-tuning (SFT)\", \"Consistent style is learned behavior, not easily prompted.\"),\n",
    "\n",
    "    (\"A developer wants an LLM to always respond in JSON.\",\n",
    "     \"Prompt Engineering\", \"Formatting instruction handled by a clear system prompt.\"),\n",
    "\n",
    "    (\"A hospital needs an LLM referencing latest drug interaction data.\",\n",
    "     \"RAG\", \"Medical data updates frequently. Fine-tuning outdated quickly.\"),\n",
    "\n",
    "    (\"A company wants its chatbot to sound casual, not corporate.\",\n",
    "     \"Fine-tuning or Prompt Eng.\", \"Try prompting first. Fine-tune if tone is inconsistent.\"),\n",
    "]\n",
    "\n",
    "print(\"SCENARIO ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "for scenario, approach, reasoning in scenarios:\n",
    "    print(f\"\\nScenario: {scenario}\")\n",
    "    print(f\"  Best approach: {approach}\")\n",
    "    print(f\"  Reasoning: {reasoning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b66794",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 9: Troubleshooting\n",
    "\n",
    "| Problem | Likely Cause | Solution |\n",
    "|---------|-------------|----------|\n",
    "| Model confidently gives wrong facts | Knowledge gap | Add RAG with verified source documents |\n",
    "| Fine-tuned model is worse than base | Too little data or overfitting | More diverse examples; add validation set |\n",
    "| Prompt engineering gives inconsistent results | Prompt is vague | Add few-shot examples; tighten constraints |\n",
    "| RAG retrieves wrong documents | Weak retrieval or bad chunking | Upgrade embedding model; improve chunking |\n",
    "| Fine-tuning too expensive for the value | Teaching knowledge instead of behavior | Switch to RAG for facts; fine-tune only for style |\n",
    "\n",
    "### Debugging Mindset — Work Backwards From the Output\n",
    "\n",
    "When quality is poor:\n",
    "\n",
    "1. **Start from the output.** What specifically is wrong?\n",
    "2. **Is it a fact problem?** Check retrieval. Is the right context being found?\n",
    "3. **Is it a format or tone problem?** Revise the system prompt. Test with a hand-crafted \"perfect\" prompt.\n",
    "4. **Is it a data problem?** Review training data quality and coverage.\n",
    "5. **Is it a model capacity problem?** Try a larger model before adding pipeline complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e6bdf2",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 10 (Bonus): Preparing a Fine-Tuning Dataset with Hugging Face\n",
    "\n",
    "If you decide fine-tuning is justified, here is how to prepare your data. We will not run actual training (requires a GPU), but data preparation is often the hardest and most important part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebee13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Step 1: Raw training data\n",
    "raw_data = [\n",
    "    {\"instruction\": \"What are your store hours?\",\n",
    "     \"response\": \"We're open Monday-Friday 9am-6pm, Saturday 10am-4pm.\"},\n",
    "    {\"instruction\": \"Do you offer free shipping?\",\n",
    "     \"response\": \"Yes, free shipping on all orders over $75.\"},\n",
    "    {\"instruction\": \"What is your return policy?\",\n",
    "     \"response\": \"Items can be returned within 30 days with a receipt.\"},\n",
    "    {\"instruction\": \"Do you have a loyalty program?\",\n",
    "     \"response\": \"Yes, earn 1 point per dollar. 100 points = $10 off.\"},\n",
    "    {\"instruction\": \"Can I buy gift cards?\",\n",
    "     \"response\": \"Gift cards are available in $25, $50, and $100 amounts.\"},\n",
    "]\n",
    "\n",
    "# Step 2: Format into training template\n",
    "def format_example(example):\n",
    "    return {\n",
    "        \"text\": f\"### Instruction:\\n{example['instruction']}\\n\\n### Response:\\n{example['response']}\"\n",
    "    }\n",
    "\n",
    "dataset = Dataset.from_list(raw_data)\n",
    "formatted = dataset.map(format_example)\n",
    "\n",
    "print(\"Formatted example:\")\n",
    "print(formatted[0]['text'])\n",
    "print()\n",
    "\n",
    "# Step 3: Tokenize\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "tokenized = formatted.map(\n",
    "    lambda x: tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", max_length=128),\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(tokenized)}\")\n",
    "print(f\"Token count (first example): {sum(1 for t in tokenized[0]['input_ids'] if t != tokenizer.pad_token_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604be15b",
   "metadata": {},
   "source": [
    "### What Comes Next in Production\n",
    "\n",
    "After data prep, training uses Hugging Face's `Trainer`:\n",
    "\n",
    "```python\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    learning_rate=2e-5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=tokenized)\n",
    "trainer.train()\n",
    "```\n",
    "\n",
    "This requires a GPU. For parameter-efficient alternatives, look into **LoRA** and **QLoRA**, which reduce training cost by 10-100x by updating only a small fraction of weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b48cce9",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 11: Capstone Exercise\n",
    "\n",
    "Pick ONE scenario:\n",
    "\n",
    "**A.** A legal firm needs a chatbot for their 200-page employee handbook.\n",
    "\n",
    "**B.** A clothing brand wants an AI assistant that matches their playful, casual voice.\n",
    "\n",
    "**C.** An internal IT helpdesk wants to automate the 50 most common support questions.\n",
    "\n",
    "### Answer:\n",
    "\n",
    "1. **Which approach(es)?** Prompt engineering, RAG, fine-tuning, or combination?\n",
    "2. **Why?** Justify with cost, complexity, data needs, update frequency.\n",
    "3. **What data do you need?** Format and approximate size.\n",
    "4. **What could go wrong?** Two risks and mitigation strategies.\n",
    "5. **How do you measure success?** Define 2-3 metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033de0d3",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "### The Path We Followed\n",
    "\n",
    "1. A language model **predicts the next token** — nothing more.\n",
    "2. We watched it **fail** on domain-specific questions — not from incapability, but from missing knowledge.\n",
    "3. **Prompt engineering** fixed tone and format, but could not inject facts.\n",
    "4. **RAG** solved the knowledge problem by retrieving information at query time.\n",
    "5. We asked: **what's still missing?** Only then did fine-tuning become relevant — for behavior and style that prompting cannot capture.\n",
    "6. We confronted the **cost reality** — fine-tuning is powerful but expensive, and often unnecessary.\n",
    "\n",
    "### Key Principles\n",
    "\n",
    "- Most problems are **knowledge gaps**, not capability gaps. Try RAG first.\n",
    "- Fine-tuning is a **last resort**, not a first instinct.\n",
    "- Fine-tuning reinforces **patterns the model has partially seen** — it is not teaching from scratch.\n",
    "- The best systems **combine approaches**: RAG for facts, prompting for structure, fine-tuning for style.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Embeddings and vector databases** — Build production RAG (FAISS, ChromaDB, Pinecone)\n",
    "- **LoRA and QLoRA** — Parameter-efficient fine-tuning\n",
    "- **Agents** — LLMs combined with tools (search, code execution, APIs)\n",
    "- **DPO paper** — [arxiv.org/abs/2305.18290](https://arxiv.org/abs/2305.18290)\n",
    "- **Hugging Face model hub** — [huggingface.co/models](https://huggingface.co/models)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aidi-2001 (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
